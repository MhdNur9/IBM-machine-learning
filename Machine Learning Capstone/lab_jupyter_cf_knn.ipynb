{"cells":[{"cell_type":"markdown","id":"e928f43d-3c2a-49aa-870b-18f8d6626fac","metadata":{},"outputs":[],"source":["\u003cp style=\"text-align:center\"\u003e\n","    \u003ca href=\"https://skills.network/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01\" target=\"_blank\"\u003e\n","    \u003cimg src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  /\u003e\n","    \u003c/a\u003e\n","\u003c/p\u003e\n"]},{"cell_type":"markdown","id":"3928bf7a-7083-46e9-9af4-05bdd762c2bb","metadata":{},"outputs":[],"source":["# **Collaborative Filtering based Recommender System using K Nearest Neighbor**\n"]},{"cell_type":"markdown","id":"125decae-3a0e-426a-b97a-21f52ca77e1b","metadata":{},"outputs":[],"source":["Estimated time needed: **60** minutes\n"]},{"cell_type":"markdown","id":"4d537c58-5c0a-4a13-9b5b-db203821511b","metadata":{},"outputs":[],"source":["Collaborative filtering is probably the most commonly used recommendation algorithm, there are two main types of methods: \n"," - **User-based** collaborative filtering is based on the user similarity or neighborhood\n"," - **Item-based** collaborative filtering is based on similarity among items\n"]},{"cell_type":"markdown","id":"0b871192-3684-48a1-a5e3-9805a184731e","metadata":{},"outputs":[],"source":["They both work similarly, let's briefly explain how user-based collaborative filtering works.\n"]},{"cell_type":"markdown","id":"475889be-86a8-4df0-b876-f00204f7acb3","metadata":{},"outputs":[],"source":["User-based collaborative filtering looks for users who are similar. This is very similar to the user clustering method done previously; where we employed explicit user profiles to calculate user similarity. However, the user profiles may not be available, so how can we determine if two users are similar?\n"]},{"cell_type":"markdown","id":"14e6de84-db0c-4ac7-9ccc-9d98a3a6cf72","metadata":{},"outputs":[],"source":["#### User-item interaction matrix \n"]},{"cell_type":"markdown","id":"2427c500-0069-4467-b11b-bf2559abd555","metadata":{},"outputs":[],"source":["For most collaborative filtering-based recommender systems, the main dataset format is a 2-D matrix called the user-item interaction matrix. In the matrix,  its row is labeled as the user id/index and column labelled to be the item id/index, and the element `(i, j)` represents the rating of user `i` to item `j`.  \n","\n","Below is a simple example of a user-item interaction matrix:\n"]},{"cell_type":"markdown","id":"a798e400-65db-4fa2-98fe-0580fdbadeee","metadata":{},"outputs":[],"source":["![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/user_item_matrix.png)\n"]},{"cell_type":"markdown","id":"ef61df8e-2df8-4559-9452-f54c69f037bd","metadata":{},"outputs":[],"source":["#### KNN-based collaborative filtering\n"]},{"cell_type":"markdown","id":"6757c0cb-d445-4cdf-ad78-870a3d32654a","metadata":{},"outputs":[],"source":["As we can see from above, each row vector represents the rating history of a user and each column vector represents the users who rated the item. A user-item interaction matrix is usually very sparse as you can imagine one user very likely only interacts with a very small subset of items and one item is very likely to be interacted by a small subset of users.\n"]},{"cell_type":"markdown","id":"96746046-dee6-4a90-86d4-33bbf98cd1ae","metadata":{},"outputs":[],"source":["Now to determine if two users are similar, we can simply calculate the similarities between their row vectors in the interaction matrix. Then based on the similarity measurements, we can find the `k` nearest neighbor as the similar users.\n"]},{"cell_type":"markdown","id":"aaae5435-2783-437a-b8cb-fe7703f3587e","metadata":{},"outputs":[],"source":["Item-based collaborative filtering works similarly, we just need to look at the user-item matrix vertically. Instead of finding similar users, we are trying to find similar items (courses). If two courses are enrolled by two groups of similar users, then we could consider the two items are similar and use the known ratings from the other users to predict the unknown ratings.\n"]},{"cell_type":"markdown","id":"0776b5e2-3751-4ed7-85d9-8806d22033a3","metadata":{},"outputs":[],"source":["If we formulate the KNN based collaborative filtering,  the predicted rating of user $u$ to item $i$, $\\hat{r}_{ui}$ is given by:\n"]},{"cell_type":"markdown","id":"70324c3c-4d84-40db-8ec5-617d658e73b9","metadata":{},"outputs":[],"source":["**User-based** collaborative filtering:\n"]},{"cell_type":"markdown","id":"dbb1ef51-0703-4612-9d8c-e591b2ba4d17","metadata":{},"outputs":[],"source":["$$\\hat{r}_{ui} = \\frac{\n","\\sum\\limits_{v \\in N^k_i(u)} \\text{similarity}(u, v) \\cdot r_{vi}}\n","{\\sum\\limits_{v \\in N^k_i(u)} \\text{similarity}(u, v)}$$\n"]},{"cell_type":"markdown","id":"df4b26f6-6a13-41eb-9869-0163caee3350","metadata":{},"outputs":[],"source":["**Item-based** collaborative filtering:\n"]},{"cell_type":"markdown","id":"ed171a30-61ee-4891-9de6-f26ff4a8f14c","metadata":{},"outputs":[],"source":["$$\\hat{r}_{ui} = \\frac{\n","\\sum\\limits_{j \\in N^k_u(i)} \\text{similarity}(i, j) \\cdot r_{uj}}\n","{\\sum\\limits_{j \\in N^k_u(i)} \\text{similarity}(i, j)}$$\n"]},{"cell_type":"markdown","id":"bfa6f666-2239-4a85-a465-a979c340f5fb","metadata":{},"outputs":[],"source":["Here $N^k_i(u)$ notates the nearest k neighbors of $u$.\n"]},{"cell_type":"markdown","id":"de3ec97b-9894-41f9-a3f9-63c182cb61d3","metadata":{},"outputs":[],"source":["Let's illustrate how the equation works using a simple example. From the above figure, suppose we want to predict the rating of `user6` to item `Machine Learning Capstone` course. After some similarity measurements, we found that k = 4 nearest neighbors: `user2, user3, user4, user5` with similarities in array ```knn_sims```:\n"]},{"cell_type":"code","id":"1e4bf322-aeb9-4d1f-972d-65f12000c9c2","metadata":{},"outputs":[],"source":["import numpy as np\nimport math"]},{"cell_type":"code","id":"207d38d4-56bc-4389-b02a-ee0a114e6a8c","metadata":{},"outputs":[],"source":["# An example similarity array stores the similarity of user2, user3, user4, and user5 to user6\nknn_sims = np.array([0.8, 0.92, 0.75, 0.83])"]},{"cell_type":"markdown","id":"cb570baa-55ea-4c67-b28e-1f3af3980d5d","metadata":{},"outputs":[],"source":["Also their rating on the `Machine Learning Capstone` course are:\n"]},{"cell_type":"code","id":"514dede5-0adf-48e7-a5e7-5d6101b5f373","metadata":{},"outputs":[],"source":["# 2.0 means audit and 3.0 means complete the course\nknn_ratings = np.array([3.0, 3.0, 2.0, 3.0]) "]},{"cell_type":"markdown","id":"0317cc2e-e1ae-466b-b48c-7f6148c4dcc0","metadata":{},"outputs":[],"source":["So the predicted rating of `user6` to item `Machine Learning Capstone` course can be calculated as:\n"]},{"cell_type":"code","id":"78f9ed73-0024-44e2-9ff5-da12cace0c56","metadata":{},"outputs":[],"source":["r_u6_ml =  np.dot(knn_sims, knn_ratings)/ sum(knn_sims)\nr_u6_ml"]},{"cell_type":"markdown","id":"a15b8a5c-597b-4536-be00-6e9e703e6519","metadata":{},"outputs":[],"source":["If we already know the true rating to be 3.0, then we get a prediction error RMSE (Rooted Mean Squared Error) as:\n"]},{"cell_type":"code","id":"ae8ec200-0cb1-4471-aa3c-336574a2d7dc","metadata":{},"outputs":[],"source":["true_rating = 3.0\nrmse = math.sqrt(true_rating - r_u6_ml) ** 2\nrmse"]},{"cell_type":"markdown","id":"9fafb268-fee3-4ad9-8e47-1282384006e0","metadata":{},"outputs":[],"source":["The predicted rating is around 2.7 (close to 3.0 with RMSE 0.22), which indicates that `user6` is also likely to complete the course `Machine Learning Capstone`. As such, we may recommend it to user6 with high confidence.\n"]},{"cell_type":"markdown","id":"ef9fd4ce-f76f-408f-836b-72126b65ace7","metadata":{},"outputs":[],"source":["## Objectives\n"]},{"cell_type":"markdown","id":"37249a40-8e73-4042-925c-4142ee0b22f2","metadata":{},"outputs":[],"source":["After completing this lab you will be able to:\n"]},{"cell_type":"markdown","id":"a5f8f400-d40e-4b39-acc6-5e812b470fe5","metadata":{},"outputs":[],"source":["* Perform KNN-based collaborative filtering on the user-item interaction matrix\n"]},{"cell_type":"markdown","id":"76354925-fb3a-4570-8713-d15878a6ce3a","metadata":{},"outputs":[],"source":["----\n"]},{"cell_type":"markdown","id":"0d5b1e6e-3007-4c67-be24-40ff203e5351","metadata":{},"outputs":[],"source":["### Load and exploring dataset\n"]},{"cell_type":"markdown","id":"5d7633e5-9c78-4be5-ad10-e837d7a820bb","metadata":{},"outputs":[],"source":["Let's first load our dataset, i.e., a user-item (learn-course) interaction matrix\n"]},{"cell_type":"code","id":"bf23212e-f7cb-42ad-af36-d2237bc2b7ff","metadata":{},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","id":"3793dabf-08a5-4908-9dc1-05efb076afc7","metadata":{},"outputs":[],"source":["rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/datasets/ratings.csv\"\nrating_df = pd.read_csv(rating_url)"]},{"cell_type":"code","id":"b6d21845-baa6-425a-b123-c4786fa205dd","metadata":{},"outputs":[],"source":["rating_df.head()"]},{"cell_type":"markdown","id":"f21b6083-22de-4616-80ab-17bb0eb0d0f9","metadata":{},"outputs":[],"source":["The dataset contains three columns, `user id` (learner), `item id`(course), and `rating`(enrollment mode). \n","\n","Note that this matrix is presented as the dense or vertical form, and you may convert it to a sparse matrix using `pivot` :\n"]},{"cell_type":"code","id":"a41cda2a-90c2-40c5-bcb5-c3c6273f435c","metadata":{},"outputs":[],"source":["rating_sparse_df = rating_df.pivot(index='user', columns='item', values='rating').fillna(0).reset_index().rename_axis(index=None, columns=None)\nrating_sparse_df.head()"]},{"cell_type":"markdown","id":"ab7506ea-06e3-4097-b720-b24f3ff045f8","metadata":{},"outputs":[],"source":["Usually, the dense format is more preferred as it saves a lot of storage and memory space. While the benefit of the sparse matrix is it is in the nature matrix format and you could apply computations such as cosine similarity directly.\n"]},{"cell_type":"markdown","id":"f756404f-5716-4865-abd1-a4800944ca53","metadata":{},"outputs":[],"source":["Next, you need to perform KNN-based collaborative filtering on the user-item interaction matrix. \n","You may choose one of the two following implementation options of KNN-based collaborative filtering. \n","- The first one is to use `scikit-surprise` which is a popular and easy-to-use Python recommendation system library. \n","- The second way is to implement it with standard `numpy`, `pandas`, and `sklearn`. You may need to write a lot of low-level implementation code along the way.\n"]},{"cell_type":"markdown","id":"2a6f7640-354c-4d0b-aec8-0da08f9691f6","metadata":{},"outputs":[],"source":["## Implementation Option 1: Use **Surprise** library (recommended)\n"]},{"cell_type":"markdown","id":"97839640-0431-4812-bd63-7c10ddf1a894","metadata":{},"outputs":[],"source":["*Surprise* is a Python sci-kit library for recommender systems. It is simple and comprehensive to build and test different recommendation algorithms. \n","\n","First, let's install it:\n"]},{"cell_type":"code","id":"a86d0b7d-d2dc-427e-9c83-1f6353260ff9","metadata":{},"outputs":[],"source":["!pip install scikit-surprise==1.1.1"]},{"cell_type":"markdown","id":"95e9bad3-9e32-4a0e-8de0-10463e725bf9","metadata":{},"outputs":[],"source":["Now we import required classes and methods\n"]},{"cell_type":"code","id":"0718afc6-17ba-475d-8f1e-a9de1b4ccf76","metadata":{},"outputs":[],"source":["from surprise import KNNBasic\nfrom surprise import Dataset, Reader\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy"]},{"cell_type":"markdown","id":"16bd2073-cb62-4b3a-8e8d-779cbcef99d1","metadata":{},"outputs":[],"source":["Then, let's take a look at a code example how easily to perform KNN collaborative filtering on a sample movie review dataset, which contains about 100k movie ratings from users.\n"]},{"cell_type":"code","id":"15cb659c-2a9a-443c-a3ee-548d9eba010f","metadata":{},"outputs":[],"source":["# Load the movielens-100k dataset (download it if needed),\ndata = Dataset.load_builtin('ml-100k', prompt=False)\n\n# sample random trainset and testset\n# test set is made of 25% of the ratings.\ntrainset, testset = train_test_split(data, test_size=.25)\n\n# We'll use the famous KNNBasic algorithm.\nalgo = KNNBasic()\n\n# Train the algorithm on the trainset, and predict ratings for the testset\nalgo.fit(trainset)\npredictions = algo.test(testset)\n\n# Then compute RMSE\naccuracy.rmse(predictions)"]},{"cell_type":"markdown","id":"2b5da4d2-4848-4159-886f-706801466bec","metadata":{},"outputs":[],"source":["As you can see, just a couple of lines and you can apply KNN collaborative filtering on the sample movie lens dataset. The main evaluation metric is `Root Mean Square Error (RMSE)` which is a very popular rating estimation error metric used in recommender systems as well as many regression model evaluations.\n"]},{"cell_type":"markdown","id":"9ddd74a5-6c95-41ee-9a72-e5348ee873f5","metadata":{},"outputs":[],"source":["Now, let's load our own course rating dataset:\n"]},{"cell_type":"code","id":"98d7a325-080f-4bd7-b6bc-9677b945bb56","metadata":{},"outputs":[],"source":["rating_df.to_csv(\"course_ratings.csv\", index=False)\n# Read the course rating dataset with columns user item rating\nreader = Reader(\n        line_format='user item rating', sep=',', skip_lines=1, rating_scale=(2, 3))\n\ncoruse_dataset = Dataset.load_from_file(\"course_ratings.csv\", reader=reader)"]},{"cell_type":"markdown","id":"952e8c85-d8c8-4289-9851-2d2ab3f03bf1","metadata":{},"outputs":[],"source":["We split it into trainset and testset:\n"]},{"cell_type":"code","id":"3bd804ef-562d-424a-8421-7a9a12be4237","metadata":{},"outputs":[],"source":["trainset, testset = train_test_split(coruse_dataset, test_size=.3)"]},{"cell_type":"markdown","id":"f64f9d56-664b-4b3d-972c-9cbae6e7c28f","metadata":{},"outputs":[],"source":["then check how many users and items we can use to fit a KNN model:\n"]},{"cell_type":"code","id":"ca0e74db-0afb-4b0f-bfca-c89dc1da7dbd","metadata":{},"outputs":[],"source":["print(f\"Total {trainset.n_users} users and {trainset.n_items} items in the trainingset\")"]},{"cell_type":"markdown","id":"7aa7cf31-026d-44e0-8c99-93270f891389","metadata":{},"outputs":[],"source":["### TASK: Perform KNN-based collaborative filtering on the user-item interaction matrix\n"]},{"cell_type":"markdown","id":"c6942531-30b4-428f-87cc-6c1a75e44566","metadata":{},"outputs":[],"source":["_TODO: Fit the KNN-based collaborative filtering model using the trainset and evaluate the results using the testset:_\n"]},{"cell_type":"code","id":"c2a8d6c6-a686-4e3f-b4fe-21cd3633f2ad","metadata":{},"outputs":[],"source":["## WRITE YOUR CODE HERE:\n\n\n# - Define a KNNBasic() model\n# Note there are some arguments such as:\n# max_k and min_k, representing the max and min number of neighors for rating estimations\n# sim_option, representing similarity measurement such as cosine and whether you want it to be user_based or items_based \n# e.g., sim_option = {\n#        'name': 'cosine', 'user_based': False,\n#    }\n#\n# more KNN model hyperparamets can be found here:\n# https://surprise.readthedocs.io/en/stable/knn_inspired.html\n# \n# You may try different hyperparamet combinations to see which one has the best performance\n\n\n# - Train the KNNBasic model on the trainset, and predict ratings for the testset\n\n# - Then compute RMSE\n"]},{"cell_type":"markdown","id":"123eab83-9118-400e-8612-fef73bdf23b4","metadata":{},"outputs":[],"source":["\u003cdetails\u003e\n","    \u003csummary\u003eClick here for Hints\u003c/summary\u003e\n","\n","* Create a model by calling `KNNBasic()` class. \n","* Fit it with `trainset` by using `model.fit(trainset)`.  \n","* Record predictions to the `testset`  by using `model.test(testset).\n","* Compute the accuracy by using `accuracy.rmse(predictions)`\n"]},{"cell_type":"markdown","id":"72c4cf8f-77ae-45a0-b632-5e8f6790435a","metadata":{},"outputs":[],"source":["To learn more detailed usages about _Surprise_ library, visit its website from [here](https://surprise.readthedocs.io/en/stable/getting_started.html?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01)\n"]},{"cell_type":"markdown","id":"287313d6-5c94-4ebf-a35e-f1fdaa276245","metadata":{},"outputs":[],"source":["## Implementation Option 2: Use `numpy`, `pandas`, and `sklearn`\n"]},{"cell_type":"markdown","id":"0a8f3d08-343e-4e37-9192-95c4acd7ec65","metadata":{},"outputs":[],"source":["If you do not prefer the one-stop Suprise solution and want more hardcore coding practices, you may implement the KNN model using `numpy`, `pandas`, and possibly `sklearn`:\n"]},{"cell_type":"code","id":"c3bb3369-c586-441c-bb33-c8b79ff2e855","metadata":{},"outputs":[],"source":["## WRITE YOUR CODE HERE:\n\n## One solution could be:\n## - Calculate the similarity between two users using their rating history (the row vectors of interaction matrix)\n\n## - Build a similarity matrix for each pair of users with the training dataset\n\n## - For each user, find its k nearest neighbors in the sim matrix\n\n## - For each rating in the test dataset, estimate its rating using the KNN collaborative filtering equations shown before\n\n## - Calculate RMSE for the entire test dataset\n\n"]},{"cell_type":"markdown","id":"bc531ac4-7cb0-4863-b49e-2c18a83a49c9","metadata":{},"outputs":[],"source":["## Summary\n"]},{"cell_type":"markdown","id":"47e7ecd2-1fad-48db-933c-58ff928bea56","metadata":{},"outputs":[],"source":["\n","In this lab, you have learned and implemented KNN-based collaborative filtering. It is probably the simplest but very effective and intuitive collaborative filtering algorithm. Since it is based on KNN, it inherits the main characteristics of KNN such as memory-intensive because you need to maintain a huge similarity matrix among users or items. In the future labs, we will learn other types of collaborative filtering which do not rely on such a huge similarity matrix to make rating predictions.\n"]},{"cell_type":"markdown","id":"100aface-1cdc-4fe4-b1e6-33f10094bd1b","metadata":{},"outputs":[],"source":["## Authors\n"]},{"cell_type":"markdown","id":"ad1a2ab5-de30-4990-a8e2-44c1f6cee424","metadata":{},"outputs":[],"source":["[Yan Luo](https://www.linkedin.com/in/yan-luo-96288783/?utm_medium=Exinfluencer\u0026utm_source=Exinfluencer\u0026utm_content=000026UJ\u0026utm_term=10006555\u0026utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01)\n"]},{"cell_type":"markdown","id":"4e388d25-3162-4072-82cd-365713606f03","metadata":{},"outputs":[],"source":["### Other Contributors\n"]},{"cell_type":"markdown","id":"47d5f5fa-b5e4-45f5-b3c4-af46b8ef0ec2","metadata":{},"outputs":[],"source":["## Change Log\n"]},{"cell_type":"markdown","id":"2936aa2e-5ec3-4d8a-a798-b19c9b342338","metadata":{},"outputs":[],"source":["|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n","|-|-|-|-|\n","|2021-10-25|1.0|Yan|Created the initial version|\n"]},{"cell_type":"markdown","id":"868dddd4-61e6-4ce1-84e7-4e9b039b37c4","metadata":{},"outputs":[],"source":["Copyright © 2021 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":""}},"nbformat":4,"nbformat_minor":4}