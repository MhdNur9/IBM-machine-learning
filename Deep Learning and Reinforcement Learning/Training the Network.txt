import warnings
warnings.simplefilter('ignore')

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' 

import pathlib
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

import PIL
from PIL import Image, ImageOps
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras import layers

from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
def plot_activations_multilayer(num_layers, images_per_row, classifier, activations):
    layer_names = []
    for layer in classifier.layers[:num_layers]:
        layer_names.append(layer.name + ' layer')  # Names of the layers, so you can have them as part of your plot
    for layer_name, layer_activation in zip(layer_names, activations):  # Displays the feature maps
        n_features = layer_activation.shape[-1]  # Number of features in the feature map
        size = layer_activation.shape[1]  # The feature map has shape (1, size, size, n_features).
        n_cols = n_features // images_per_row # Tiles the activation channels in this matrix
        display_grid = np.zeros((size * n_cols, images_per_row * size))
        for col in range(n_cols): # Tiles each filter into a big horizontal grid
            for row in range(images_per_row):
                channel_image = layer_activation[0, :, :,
                                                 col * images_per_row + row]
                display_grid[col * size : (col + 1) * size, # Displays the grid
                             row * size : (row + 1) * size] = channel_image
        scale = 2. / size
        plt.figure(figsize=(scale*display_grid.shape[1],
                            scale*display_grid.shape[0]))
        plt.title(layer_name)
        plt.grid(False)
        plt.imshow(display_grid, aspect='auto', cmap='viridis')
import skillsnetwork

dataset_url = "https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML311-Coursera/datasets/flower_photos.tgz"
await skillsnetwork.prepare(dataset_url, overwrite=True)
data_dir = Path("flower_photos")

for folder in data_dir.glob('[!LICENSE]*'):
    print('The', folder.name, 'folder has',
          len(list(folder.glob('*.jpg'))), 'pictures')

image_count = len(list(data_dir.glob('*/*.jpg')))
print(image_count, 'total images')
img_width = 150
img_height = 150

batch_size = 64
epochs = 10
# Plotting out some images we have
pics = list()
pics_arr = list()
p_class = list()

plt.figure(figsize=(20,5))
for idx, folder in enumerate(data_dir.glob('[!LICENSE]*')):
    cat = list(data_dir.glob(folder.name + '/*'))
    pic = PIL.Image.open(str(cat[0])).resize((img_width, img_height))
    pic_arr = np.array(pic)
    clss = folder.name
    
    plt.subplot(1,5,idx+1)
    plt.imshow(pic)
    plt.title(clss)
    plt.axis('off')
    
    pics.append(pic)
    pics_arr.append(pic_arr)
    p_class.append(clss)
    
train_gen = ImageDataGenerator(validation_split=0.2, 
                               rescale=1.0/255.0,
                                width_shift_range=0.2, # 0.1
                                height_shift_range=0.2, # 0.1
                                horizontal_flip=True)
train_set = train_gen.flow_from_directory(
                               directory=data_dir,
                               seed=10,
                               class_mode='sparse',
                               batch_size=batch_size,
                               shuffle=True,
                               target_size=(img_height, img_width),
                               subset='training')
val_gen = ImageDataGenerator(validation_split=0.2, 
                                rescale=1.0/255.0,
                                width_shift_range=0.2, 
                                height_shift_range=0.2,
                                horizontal_flip=True)
val_set = val_gen.flow_from_directory(
                               directory=data_dir,
                               seed=10,
                               class_mode='sparse',
                               batch_size=batch_size,
                               shuffle=True,
                               target_size=(img_height, img_width),
                               subset='validation')
class_names = {y: x for x, y in val_set.class_indices.items()}
class_names
classifier = Sequential()
classifier.add(Conv2D(32, (5, 5), padding='same', input_shape = (img_width, img_height, 3), activation = 'relu'))
classifier.add(MaxPooling2D(pool_size=(2, 2)))
classifier.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))
classifier.add(Conv2D(32, (3, 3), padding='same', activation = 'relu'))
classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))
classifier.add(Conv2D(32, (3, 3), padding='same', activation='relu'))
classifier.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))
classifier.build((1,img_width, img_height,3))
classifier.summary()
# display the sample image
img_tensor = np.array(pics_arr[2], dtype='int')
plt.imshow(img_tensor)
img_tensor = np.expand_dims(img_tensor, axis=0)
y = classifier.predict(img_tensor)
print(f"The predicted output of the sample image has a shape of {y.shape}.")
layer_outputs = [layer.output for layer in classifier.layers] 
activation_model = Model(inputs=classifier.input, outputs=layer_outputs) 
activations = activation_model.predict(img_tensor)

plot_activations_multilayer(8, 8, classifier, activations)
classifier.add(Flatten()) 
classifier.add(Dense(units = 512, activation = 'relu'))
classifier.add(Dense(units = 5, activation = 'softmax'))
classifier.summary()
classifier.compile(optimizer='adam', 
              loss="sparse_categorical_crossentropy",
              metrics=['accuracy'])
classifier.fit(
  train_set,
  validation_data=val_set,
  epochs=epochs
)
for layer in classifier.layers:
    if 'conv2d' in layer.name:
        kernels, biases = layer.get_weights()
        print(f"layer name: {layer.name}, num of kernels: {kernels.shape[-1]}, kernel shape: {kernels.shape[:2]}, kernel depth: {kernels.shape[2]}")
for layer in classifier.layers:
    if 'conv2d' in layer.name:
        name = layer.name

        kernels, _ = layer.get_weights()
        k_min, k_max = kernels.min(), kernels.max()
        kernels = (kernels - k_min) / (k_max - k_min)

        for i in range(4):
            kernel = kernels[:,:,:,i]
            fig = plt.figure(figsize=(5, 2))
            fig.suptitle(f"{name}, kernel {i+1}", fontsize=15)

            for j in range(3):
                plt.subplot(1, 3, j+1)
                plt.imshow(kernel[:,:,j], cmap='gray')
                plt.xticks([])
                plt.yticks([])
plt.imshow(kernels[:,:,2,3], cmap='gray')
layer_outputs = [layer.output for layer in classifier.layers]
activation_model = Model(inputs=classifier.input, outputs=layer_outputs)
# let's pick a sample image 
img_tensor = pics_arr[1]
plt.imshow(np.array(img_tensor, dtype='int'))
img_tensor = np.expand_dims(img_tensor, axis=0)

activations = activation_model.predict(img_tensor)[:6]

plot_activations_multilayer(7,8,classifier,activations)
y = classifier.predict(img_tensor)
label = class_names[np.argmax(y)]

plt.imshow(img_tensor.reshape((img_width,img_height,3)).astype("uint8"))
plt.title(f"Predicted class is: {label}", fontsize=13)
